{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc23fa13",
   "metadata": {},
   "source": [
    "# Movie Analysis tutorial\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/georgia-tech-db/eva/blob/master/tutorials/movie_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c8d8c",
   "metadata": {},
   "source": [
    "### Launch EVA DB\n",
    "Run the command `eva_server` in the server where you want to deploy EVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b2a6f",
   "metadata": {},
   "source": [
    "### Establish Connection With Eva DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e83a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from eva.server.db_api import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "connection = connect(host = '0.0.0.0', port = 5432) # hostname, port of the server where EVADB is running\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0509c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download UDFS\n",
    "!wget https://www.dropbox.com/s/me2dif7393twdx7/gender.py\n",
    "!wget https://www.dropbox.com/s/erebvb3nxn9vycl/face_detector.py\n",
    "\n",
    "# Download models\n",
    "!wget https://www.dropbox.com/s/0y291evpqdfmv2z/gender.pth\n",
    "\n",
    "# Download videos\n",
    "!wget https://www.dropbox.com/s/f5447euuuis1vdy/test.mp4\n",
    "!wget https://www.dropbox.com/s/f5447euuuis1vdy/short.mp4\n",
    "!wget https://www.dropbox.com/s/xf8b1vsrfa03a14/short2.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64d3b6",
   "metadata": {},
   "source": [
    "### Load the example video to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"LOAD FILE 'short2.mp4' INTO TIKTOK;\")\n",
    "response = cursor.fetch_all()\n",
    "print(response)\n",
    "cursor.execute(\"\"\"SELECT id FROM TIKTOK WHERE id < 5\"\"\")\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450f505",
   "metadata": {},
   "source": [
    "### Visualize Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"short2.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686adeb5",
   "metadata": {},
   "source": [
    "### Create GenderCNN UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"CREATE UDF IF NOT EXISTS \n",
    "                  GenderCNN\n",
    "                  INPUT (data NDARRAY UINT8(3, 224, 224)) \n",
    "                  OUTPUT (label TEXT(10)) TYPE  \n",
    "                  Classification IMPL 'gender.py';\n",
    "        \"\"\")\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd789e",
   "metadata": {},
   "source": [
    "### Run Face Detection on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bdcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT id, FaceDetector(data).bboxes FROM TIKTOK WHERE id < 30\"\"\")\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6b68e",
   "metadata": {},
   "source": [
    "### Detect Gender of the faces in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT id, bbox, GenderCNN(Crop(data, bbox)) FROM TIKTOK JOIN LATERAL  Unnest(FaceDetector(data)) AS Face(bbox, conf)  WHERE id < 10;\"\"\")\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ed233",
   "metadata": {},
   "source": [
    "### Visualize output of Gender on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def annotate_video(detections, input_video_path, output_video_path):\n",
    "    color=(0,255,0)\n",
    "    thickness=3\n",
    "\n",
    "    vcap = cv2.VideoCapture(input_video_path)\n",
    "    width = int(vcap.get(3))\n",
    "    height = int(vcap.get(4))\n",
    "    fps = vcap.get(5)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V') #codec\n",
    "    video=cv2.VideoWriter(output_video_path, fourcc, fps, (width,height))\n",
    "\n",
    "    frame_id = 0\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = vcap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "\n",
    "    while ret:\n",
    "        df = detections\n",
    "        df = df[['Face.bbox', 'gendercnn.label']][df['tiktok.id'] == frame_id]\n",
    "        \n",
    "        if df.size:\n",
    "            for bbox, label in df.values:\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                img=cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness) # object bbox\n",
    "                cv2.putText(img, str(label), (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, thickness-1) # object label\n",
    "            video.write(img)\n",
    "\n",
    "        frame_id+=1\n",
    "        ret, frame = vcap.read()\n",
    "\n",
    "    video.release()\n",
    "    vcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23159f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets\n",
    "from ipywidgets import Video\n",
    "input_path = 'short2.mp4'\n",
    "output_path = 'annotated_short2.mp4'\n",
    "annotate_video(response.batch.frames, input_path, output_path)\n",
    "Video.from_file(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('test_eva_db': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1dbd882c97e8cc10d04c788d83c90a5bd7f07f60066c26f3fe8ea9a0af7ed11a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
